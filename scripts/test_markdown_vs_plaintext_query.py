"""
æ¸¬è©¦ Markdown vs Plain Text æŸ¥è©¢æ•ˆæœå°æ¯”

æ¯”è¼ƒçµæ§‹åŒ– Markdown å’Œç´”æ–‡å­—ä¸Šå‚³å° Gemini File Search æŸ¥è©¢æ•ˆæœçš„å½±éŸ¿
"""

import os
import time
import json
from pathlib import Path
import google.generativeai as genai

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
api_key = os.getenv('GEMINI_API_KEY')

# å¦‚æœæ²’æœ‰å¾ç’°å¢ƒè®Šæ•¸å–å¾—,å˜—è©¦å¾ .env æª”æ¡ˆè®€å–
if not api_key:
    env_file = Path(__file__).parent.parent / '.env'
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                if line.startswith('GEMINI_API_KEY='):
                    api_key = line.split('=', 1)[1].strip().strip('"').strip("'")

if not api_key:
    raise ValueError("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š GEMINI_API_KEY")

genai.configure(api_key=api_key)

# Store IDs
MARKDOWN_STORE_ID = 'fileSearchStores/fscpenalties-tu709bvr1qti'  # Markdown ç‰ˆæœ¬
PLAINTEXT_STORE_ID = None  # å¾…ç¢ºèªæ˜¯å¦å­˜åœ¨

# æ¸¬è©¦æŸ¥è©¢è¨­è¨ˆ
TEST_QUERIES = [
    {
        'name': 'å…·é«”äº‹å¯¦æŸ¥è©¢',
        'query': 'è‘£äº‹å‡ºå·®å ±éŠ·ç¼ºå¤±',
        'expected': 'æ‡‰è©²æ‰¾åˆ°å…¨çƒäººå£½è‘£äº‹é•·å‰¯è‘£äº‹é•·å‡ºåœ‹è€ƒå¯Ÿçš„æ¡ˆä¾‹'
    },
    {
        'name': 'æ³•å¾‹ä¾æ“šæŸ¥è©¢',
        'query': 'é•åä¿éšªæ³•ç¬¬148æ¢ä¹‹3',
        'expected': 'æ‡‰è©²æ‰¾åˆ°é•åå…§éƒ¨æ§åˆ¶åˆ¶åº¦çš„æ¡ˆä¾‹'
    },
    {
        'name': 'è™•åˆ†é‡‘é¡æŸ¥è©¢',
        'query': 'ç½°æ¬¾300è¬å…ƒçš„è£ç½°æ¡ˆä»¶',
        'expected': 'æ‡‰è©²æ‰¾åˆ°è™•åˆ†é‡‘é¡ç‚º300è¬å…ƒçš„æ¡ˆä¾‹'
    },
    {
        'name': 'è¢«è™•åˆ†äººæŸ¥è©¢',
        'query': 'å…¨çƒäººå£½ä¿éšªå…¬å¸çš„é•è¦æ¡ˆä¾‹',
        'expected': 'æ‡‰è©²æ‰¾åˆ°å…¨çƒäººå£½çš„è£ç½°æ¡ˆä»¶'
    },
    {
        'name': 'é•è¦é¡å‹æŸ¥è©¢',
        'query': 'å…§éƒ¨æ§åˆ¶åˆ¶åº¦ç¼ºå¤±æ¡ˆä¾‹',
        'expected': 'æ‡‰è©²æ‰¾åˆ°å…§éƒ¨æ§åˆ¶ç›¸é—œçš„é•è¦'
    },
    {
        'name': 'è¤‡åˆæŸ¥è©¢',
        'query': 'ä¿éšªæ¥­å…§éƒ¨æ§åˆ¶ç¼ºå¤±è¢«ç½°300è¬',
        'expected': 'æ‡‰è©²ç²¾ç¢ºæ‰¾åˆ°å…¨çƒäººå£½æ¡ˆä¾‹'
    },
    {
        'name': 'æ¨¡ç³ŠæŸ¥è©¢',
        'query': 'è‘£äº‹å‡ºåœ‹è€ƒå¯Ÿæ²’æœ‰äº‹å‰è¦åŠƒ',
        'expected': 'æ¸¬è©¦æ˜¯å¦èƒ½æ‰¾åˆ°ç›¸é—œæè¿°'
    }
]


def query_file_search_store(store_id: str, query: str, model_name: str = 'gemini-2.0-flash-exp'):
    """
    æŸ¥è©¢ Gemini File Search Store

    Args:
        store_id: File Search Store ID
        query: æŸ¥è©¢å•é¡Œ
        model_name: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        dict: åŒ…å«å›ç­”ã€ä¾†æºæ•¸é‡ã€å¼•ç”¨ç­‰è³‡è¨Š
    """
    try:
        model = genai.GenerativeModel(
            model_name=model_name,
            tools=[{
                'file_search': {
                    'file_search_store': store_id
                }
            }]
        )

        response = model.generate_content(query)

        # æå–ä¾†æºæ•¸é‡
        sources_count = 0
        citations = []

        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata'):
                metadata = candidate.grounding_metadata
                if hasattr(metadata, 'grounding_chunks'):
                    sources_count = len(metadata.grounding_chunks)

                    # æå–å¼•ç”¨è³‡è¨Š
                    for chunk in metadata.grounding_chunks:
                        if hasattr(chunk, 'retrieved_context'):
                            ctx = chunk.retrieved_context
                            citations.append({
                                'title': getattr(ctx, 'title', 'N/A'),
                                'uri': getattr(ctx, 'uri', 'N/A')
                            })

        return {
            'answer': response.text if response.text else '(ç„¡å›ç­”)',
            'sources_count': sources_count,
            'citations': citations,
            'raw_response': response
        }

    except Exception as e:
        return {
            'error': str(e),
            'answer': None,
            'sources_count': 0,
            'citations': []
        }


def run_comparison_tests():
    """åŸ·è¡Œå°æ¯”æ¸¬è©¦"""

    print("="*80)
    print("Markdown vs Plain Text æŸ¥è©¢æ•ˆæœå°æ¯”æ¸¬è©¦")
    print("="*80)
    print()

    # æª¢æŸ¥ Plain Text Store æ˜¯å¦å­˜åœ¨
    if PLAINTEXT_STORE_ID is None:
        print("âš ï¸  æ³¨æ„: Plain Text Store ID æœªè¨­å®š,åƒ…æ¸¬è©¦ Markdown Store")
        print()

    results = []

    for i, test in enumerate(TEST_QUERIES, 1):
        print(f"\n{'='*80}")
        print(f"æ¸¬è©¦ {i}/{len(TEST_QUERIES)}: {test['name']}")
        print(f"{'='*80}")
        print(f"æŸ¥è©¢: {test['query']}")
        print(f"é æœŸ: {test['expected']}")
        print()

        # æ¸¬è©¦ Markdown Store
        print("ğŸ“Š æ¸¬è©¦ Markdown Store...")
        md_result = query_file_search_store(MARKDOWN_STORE_ID, test['query'])

        print(f"  ä¾†æºæ•¸é‡: {md_result['sources_count']}")
        print(f"  å›ç­”é•·åº¦: {len(md_result.get('answer', '')) if md_result.get('answer') else 0} å­—å…ƒ")

        if md_result.get('citations'):
            print(f"  å¼•ç”¨æª”æ¡ˆ:")
            for j, citation in enumerate(md_result['citations'][:3], 1):
                print(f"    {j}. {citation['title'][:80]}")

        if md_result.get('error'):
            print(f"  âŒ éŒ¯èª¤: {md_result['error']}")

        # å¦‚æœæœ‰ Plain Text Store,ä¹Ÿæ¸¬è©¦
        pt_result = None
        if PLAINTEXT_STORE_ID:
            print("\nğŸ“Š æ¸¬è©¦ Plain Text Store...")
            time.sleep(2)  # é¿å… rate limit
            pt_result = query_file_search_store(PLAINTEXT_STORE_ID, test['query'])

            print(f"  ä¾†æºæ•¸é‡: {pt_result['sources_count']}")
            print(f"  å›ç­”é•·åº¦: {len(pt_result.get('answer', '')) if pt_result.get('answer') else 0} å­—å…ƒ")

            if pt_result.get('citations'):
                print(f"  å¼•ç”¨æª”æ¡ˆ:")
                for j, citation in enumerate(pt_result['citations'][:3], 1):
                    print(f"    {j}. {citation['title'][:80]}")

        # å„²å­˜çµæœ
        results.append({
            'test_name': test['name'],
            'query': test['query'],
            'expected': test['expected'],
            'markdown_result': md_result,
            'plaintext_result': pt_result
        })

        # é¿å… rate limit
        time.sleep(3)

    # å„²å­˜çµæœåˆ°æª”æ¡ˆ
    output_file = Path('data/test_results/markdown_vs_plaintext_comparison.json')
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        # ç§»é™¤ raw_response (ä¸å¯åºåˆ—åŒ–)
        for r in results:
            if 'markdown_result' in r and 'raw_response' in r['markdown_result']:
                del r['markdown_result']['raw_response']
            if 'plaintext_result' in r and r['plaintext_result'] and 'raw_response' in r['plaintext_result']:
                del r['plaintext_result']['raw_response']

        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n\n{'='*80}")
    print(f"æ¸¬è©¦å®Œæˆ! çµæœå·²å„²å­˜åˆ°: {output_file}")
    print(f"{'='*80}")

    # é¡¯ç¤ºæ‘˜è¦
    print("\nğŸ“Š æ¸¬è©¦æ‘˜è¦:")
    print(f"  ç¸½æ¸¬è©¦æ•¸: {len(results)}")

    md_avg_sources = sum(r['markdown_result']['sources_count'] for r in results) / len(results)
    print(f"  Markdown å¹³å‡ä¾†æºæ•¸: {md_avg_sources:.1f}")

    if PLAINTEXT_STORE_ID:
        pt_avg_sources = sum(r['plaintext_result']['sources_count'] for r in results if r['plaintext_result']) / len(results)
        print(f"  Plain Text å¹³å‡ä¾†æºæ•¸: {pt_avg_sources:.1f}")

    return results


if __name__ == '__main__':
    try:
        results = run_comparison_tests()
    except KeyboardInterrupt:
        print("\n\næ¸¬è©¦ä¸­æ–·")
    except Exception as e:
        print(f"\n\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
