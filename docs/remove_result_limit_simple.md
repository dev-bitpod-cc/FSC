# ç§»é™¤ã€Œä»¥ä¸‹åˆ—å‡ºå‰ 3 ç­†ã€é™åˆ¶ - ç°¡å–®è§£æ±ºæ–¹æ¡ˆ

## å•é¡Œ

æŸ¥è©¢çµæœé¡¯ç¤ºï¼š**ã€Œæ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä»¥ä¸‹åˆ—å‡ºå‰ 3 ç­†ã€**

## âœ… è§£æ±ºæ–¹æ¡ˆï¼ˆPrompt Engineeringï¼‰

é€™å€‹å•é¡Œæ˜¯ Gemini æ¨¡å‹è‡ªè¡Œæ±ºå®šåªé¡¯ç¤ºéƒ¨åˆ†çµæœã€‚æœ€ç°¡å–®çš„è§£æ±ºæ–¹æ³•æ˜¯**ä¿®æ”¹ system instruction**ï¼Œæ˜ç¢ºè¦æ±‚é¡¯ç¤ºæ‰€æœ‰çµæœã€‚

---

## ğŸ“ ä¿®æ”¹æ­¥é©Ÿï¼ˆFSC-Penalties-Deploy/app.pyï¼‰

### 1. æ‰¾åˆ°æŸ¥è©¢å‡½æ•¸ä¸­çš„ `system_instruction`

æœå°‹ï¼š`system_instruction` æˆ– `generate_content`

### 2. ä¿®æ”¹å‰

```python
system_instruction = """ä½ æ˜¯é‡‘ç®¡æœƒè£ç½°æ¡ˆä»¶æŸ¥è©¢åŠ©æ‰‹ã€‚
è«‹æä¾›çµæ§‹åŒ–çš„æŸ¥è©¢çµæœã€‚"""

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[...],
        temperature=0.1,
        max_output_tokens=2000,
        system_instruction=system_instruction
    )
)
```

### 3. ä¿®æ”¹å¾Œ

```python
system_instruction = """ä½ æ˜¯é‡‘ç®¡æœƒè£ç½°æ¡ˆä»¶æŸ¥è©¢åŠ©æ‰‹ã€‚

**é‡è¦æŒ‡ç¤º**ï¼š
1. è«‹åˆ—å‡ºã€Œæ‰€æœ‰ã€æ‰¾åˆ°çš„ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä¸è¦çœç•¥ä»»ä½•ä¸€ç­†
2. æ¯ç­†æ¡ˆä»¶éƒ½è¦å®Œæ•´é¡¯ç¤ºè³‡è¨Š
3. ä¸è¦ä½¿ç”¨ã€Œä»¥ä¸‹åˆ—å‡ºå‰ N ç­†ã€é€™æ¨£çš„é™åˆ¶æ€§èªå¥
4. å¦‚æœæ‰¾åˆ° X ç­†æ¡ˆä»¶ï¼Œè«‹å…¨éƒ¨åˆ—å‡º

**å›ç­”æ ¼å¼**ï¼š
æ‰¾åˆ° X ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼š

### 1. [ç¬¬ä¸€ç­†æ¡ˆä»¶åç¨±]
- **æ—¥æœŸ**ï¼š...
- **ç™¼æ–‡å­—è™Ÿ**ï¼š...
- **ä¾†æºå–®ä½**ï¼š...
- **è¢«è™•ç½°å°è±¡**ï¼š...
- **é•è¦äº‹é …**ï¼š...
- **è£ç½°é‡‘é¡**ï¼š...
- **æ³•å¾‹ä¾æ“š**ï¼š...

### 2. [ç¬¬äºŒç­†æ¡ˆä»¶åç¨±]
...

[ä»¥æ­¤é¡æ¨ï¼Œåˆ—å‡ºæ‰€æœ‰æ¡ˆä»¶]
"""

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[...],
        temperature=0.1,
        max_output_tokens=8000,  # å¢åŠ è¼¸å‡ºé™åˆ¶ä»¥å®¹ç´æ›´å¤šçµæœ
        system_instruction=system_instruction
    )
)
```

### é—œéµä¿®æ”¹é»ï¼š

1. âœ… **æ˜ç¢ºæŒ‡ç¤º**ï¼šã€Œåˆ—å‡ºæ‰€æœ‰æ‰¾åˆ°çš„æ¡ˆä»¶ï¼Œä¸è¦çœç•¥ã€
2. âœ… **ç¦æ­¢é™åˆ¶èªå¥**ï¼šã€Œä¸è¦ä½¿ç”¨ã€ä»¥ä¸‹åˆ—å‡ºå‰ N ç­†ã€ã€
3. âœ… **æä¾›æ ¼å¼ç¯„ä¾‹**ï¼šè®“æ¨¡å‹çŸ¥é“å¦‚ä½•çµ„ç¹”å¤šç­†çµæœ
4. âœ… **å¢åŠ è¼¸å‡ºé™åˆ¶**ï¼š`max_output_tokens` å¾ 2000 æé«˜åˆ° 8000

---

## ğŸ“‹ å®Œæ•´ç¯„ä¾‹ç¨‹å¼ç¢¼

```python
from google import genai
from google.genai import types
import os

def query_all_cases(question: str, store_id: str) -> dict:
    """
    åŸ·è¡Œ RAG æŸ¥è©¢ï¼ˆé¡¯ç¤ºæ‰€æœ‰çµæœï¼‰

    Args:
        question: æŸ¥è©¢å•é¡Œ
        store_id: File Search Store ID

    Returns:
        æŸ¥è©¢çµæœ
    """

    client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))

    # é—œéµï¼šæ˜ç¢ºè¦æ±‚åˆ—å‡ºæ‰€æœ‰çµæœçš„ system instruction
    system_instruction = """ä½ æ˜¯é‡‘ç®¡æœƒè£ç½°æ¡ˆä»¶æŸ¥è©¢åŠ©æ‰‹ã€‚

**é‡è¦æŒ‡ç¤º**ï¼š
1. è«‹åˆ—å‡ºã€Œæ‰€æœ‰ã€æ‰¾åˆ°çš„ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä¸è¦çœç•¥ä»»ä½•ä¸€ç­†
2. æ¯ç­†æ¡ˆä»¶éƒ½è¦å®Œæ•´é¡¯ç¤ºè³‡è¨Š
3. ä¸è¦ä½¿ç”¨ã€Œä»¥ä¸‹åˆ—å‡ºå‰ N ç­†ã€é€™æ¨£çš„é™åˆ¶æ€§èªå¥
4. å¦‚æœæ‰¾åˆ° X ç­†æ¡ˆä»¶ï¼Œè«‹å…¨éƒ¨åˆ—å‡º

**å›ç­”æ ¼å¼**ï¼š
æ‰¾åˆ° X ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼š

### 1. [ç¬¬ä¸€ç­†æ¡ˆä»¶åç¨±]
- **æ—¥æœŸ**ï¼š...
- **ç™¼æ–‡å­—è™Ÿ**ï¼š...
- **ä¾†æºå–®ä½**ï¼š...
- **è¢«è™•ç½°å°è±¡**ï¼š...
- **é•è¦äº‹é …**ï¼š...
- **è£ç½°é‡‘é¡**ï¼š...
- **æ³•å¾‹ä¾æ“š**ï¼š...

### 2. [ç¬¬äºŒç­†æ¡ˆä»¶åç¨±]
...

[ä»¥æ­¤é¡æ¨ï¼Œåˆ—å‡ºæ‰€æœ‰æ¡ˆä»¶]
"""

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=question,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    # æ ¹æ“šæ‚¨çš„å¯¦éš› API ç‰ˆæœ¬ä½¿ç”¨æ­£ç¢ºçš„èªæ³•
                    # å¯èƒ½æ˜¯ file_search æˆ– fileSearch
                    file_search=types.FileSearch(
                        file_search_store_names=[store_id]
                    )
                )
            ],
            temperature=0.1,
            max_output_tokens=8000,  # æ”¯æ´æ›´å¤šçµæœ
            system_instruction=system_instruction
        )
    )

    return {
        'text': response.text,
        'sources': _extract_sources(response)
    }

def _extract_sources(response):
    """æå–åƒè€ƒæ–‡ä»¶"""
    sources = []

    if hasattr(response, 'candidates') and response.candidates:
        candidate = response.candidates[0]
        if hasattr(candidate, 'grounding_metadata'):
            metadata = candidate.grounding_metadata
            if hasattr(metadata, 'grounding_chunks'):
                for chunk in metadata.grounding_chunks:
                    if hasattr(chunk, 'retrieved_context'):
                        context = chunk.retrieved_context
                        sources.append({
                            'filename': getattr(context, 'uri', ''),
                            'snippet': getattr(context, 'text', '')[:500]
                        })

    return sources

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == '__main__':
    store_id = 'fileSearchStores/fscpenalties-tu709bvr1qti'
    question = 'ä¸‰å•†ç¾é‚¦äººå£½ è³‡æœ¬é©è¶³ç‡'

    result = query_all_cases(question, store_id)

    print(result['text'])
    print(f"\nåƒè€ƒæ–‡ä»¶æ•¸é‡: {len(result['sources'])} ç­†")
```

---

## ğŸ¯ é æœŸæ•ˆæœ

### ä¿®æ”¹å‰
```
æ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä»¥ä¸‹åˆ—å‡ºå‰ 3 ç­†ï¼š

### 1. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2024-07-12ï¼‰
...

### 2. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2015-08-28ï¼‰
...

### 3. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2012-03-26ï¼‰
...
```

### ä¿®æ”¹å¾Œ
```
æ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼š

### 1. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2024-07-12ï¼‰
...

### 2. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2015-08-28ï¼‰
...

### 3. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2012-03-26ï¼‰
...

### 4. ä¸‰å•†ç¾é‚¦äººå£½ï¼ˆ2009-XX-XXï¼‰
...
```

---

## âœ… æ¸¬è©¦æ¸…å–®

ä¿®æ”¹å®Œæˆå¾Œï¼Œè«‹æ¸¬è©¦ï¼š

- [ ] æŸ¥è©¢ã€Œä¸‰å•†ç¾é‚¦äººå£½ è³‡æœ¬é©è¶³ç‡ã€
- [ ] ç¢ºèªé¡¯ç¤ºã€Œæ‰¾åˆ° 4 ç­†ã€ä¸”å…¨éƒ¨åˆ—å‡ºï¼ˆä¸æ˜¯ã€Œå‰ 3 ç­†ã€ï¼‰
- [ ] æ¯ç­†æ¡ˆä»¶è³‡è¨Šå®Œæ•´
- [ ] æ²’æœ‰è¢«æˆªæ–·çš„å…§å®¹
- [ ] åƒè€ƒæ–‡ä»¶å€å¡Šä¹Ÿé¡¯ç¤ºæ‰€æœ‰ä¾†æº

---

## ğŸ“š å…¶ä»–å¯èƒ½çš„èª¿æ•´

### å¦‚æœä»ç„¶åªé¡¯ç¤ºéƒ¨åˆ†çµæœ

1. **é€²ä¸€æ­¥å¢åŠ  max_output_tokens**
   ```python
   max_output_tokens=12000  # æˆ–æ›´é«˜ï¼ˆæœ€å¤§ 32768ï¼‰
   ```

2. **åœ¨æŸ¥è©¢å•é¡Œä¸­åŠ å…¥æç¤º**
   ```python
   enhanced_question = f"{question}\n\nè«‹åˆ—å‡ºæ‰€æœ‰ç›¸é—œçš„è£ç½°æ¡ˆä»¶ï¼Œä¸è¦çœç•¥ä»»ä½•ä¸€ç­†ã€‚"
   ```

3. **ä½¿ç”¨ Gemini 2.0 Flash Thinkingï¼ˆå¦‚æœå¯ç”¨ï¼‰**
   ```python
   model='gemini-2.0-flash-thinking-exp'  # å¯¦é©—æ€§æ¨¡å‹ï¼Œå¯èƒ½æœ‰æ›´å¥½çš„ç†è§£èƒ½åŠ›
   ```

---

## ğŸ“Œ é‡è¦æç¤º

1. **API è²»ç”¨**ï¼š`max_output_tokens=8000` æœƒå¢åŠ è¼¸å‡º token ä½¿ç”¨é‡
2. **å›æ‡‰æ™‚é–“**ï¼šæ›´å¤šå…§å®¹å¯èƒ½å»¶é•·æŸ¥è©¢æ™‚é–“ï¼ˆä½†é€šå¸¸å½±éŸ¿ä¸å¤§ï¼‰
3. **Streamlit é¡¯ç¤º**ï¼šç¢ºä¿å‰ç«¯ UI èƒ½å¦¥å–„é¡¯ç¤ºå¤šç­†çµæœ

---

## ğŸ”§ æ•…éšœæ’é™¤

**å•é¡Œ**ï¼šä¿®æ”¹å¾Œä»ç„¶é¡¯ç¤ºã€Œå‰ 3 ç­†ã€

**å¯èƒ½åŸå› **ï¼š
1. `system_instruction` æ²’æœ‰æ­£ç¢ºå‚³éåˆ° API
2. `max_output_tokens` å¤ªå°ï¼ˆå»ºè­°è‡³å°‘ 6000ï¼‰
3. Gemini æ¨¡å‹åˆ¤æ–·åªæœ‰ 3 ç­†çœŸæ­£ç›¸é—œ

**è§£æ±ºæ–¹æ³•**ï¼š
1. ç¢ºèª `system_instruction` åƒæ•¸æœ‰æ­£ç¢ºå‚³å…¥
2. æª¢æŸ¥ console è¼¸å‡ºï¼Œç¢ºèª API è«‹æ±‚æˆåŠŸ
3. å˜—è©¦ä¸åŒçš„æŸ¥è©¢å•é¡Œæ¸¬è©¦

---

**æ›´æ–°æ—¥æœŸ**ï¼š2025-11-15
**æ–¹æ³•**ï¼šPrompt Engineeringï¼ˆæœ€ç°¡å–®ã€æœ€æœ‰æ•ˆï¼‰
**é©ç”¨å°ˆæ¡ˆ**ï¼šFSC-Penalties-Deploy (Streamlit)
