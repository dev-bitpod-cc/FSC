# ç§»é™¤ Gemini RAG æŸ¥è©¢çµæœæ•¸é‡é™åˆ¶

## å•é¡Œæè¿°

æŸ¥è©¢çµæœé¡¯ç¤ºï¼šã€Œæ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä»¥ä¸‹åˆ—å‡ºå‰ 3 ç­†ã€

**åŸå› **ï¼šGemini API çš„ `dynamic_retrieval_config` é è¨­ `result_count = 3`

---

## è§£æ±ºæ–¹æ¡ˆ

åœ¨ **FSC-Penalties-Deploy** å°ˆæ¡ˆçš„ `app.py` ä¸­ä¿®æ”¹ Gemini API æŸ¥è©¢è¨­å®šã€‚

### ğŸ“ ä¿®æ”¹ä½ç½®

æ‰¾åˆ° `generate_content` æˆ–é¡ä¼¼çš„ Gemini API å‘¼å«ï¼Œé€šå¸¸åœ¨æŸ¥è©¢å‡½æ•¸ä¸­ã€‚

### ğŸ”§ ä¿®æ”¹æ–¹å¼

#### ä¿®æ”¹å‰ï¼ˆé™åˆ¶ 3 ç­†ï¼‰

```python
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store_id]
                )
            )
        ],
        temperature=0.1,
        max_output_tokens=2000,
        system_instruction=system_instruction
    )
)
```

#### ä¿®æ”¹å¾Œï¼ˆç§»é™¤é™åˆ¶æˆ–è¨­å®šæ›´å¤§æ•¸é‡ï¼‰

**æ–¹æ¡ˆ Aï¼šç§»é™¤é™åˆ¶ï¼ˆæ¨è–¦ï¼‰**

```python
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store_id],
                    # æ–°å¢ï¼šå‹•æ…‹æª¢ç´¢é…ç½®
                    dynamic_retrieval_config=types.DynamicRetrievalConfig(
                        mode='MODE_DYNAMIC',  # å‹•æ…‹æ¨¡å¼
                        dynamic_threshold=0.3  # ç›¸é—œæ€§é–¾å€¼ï¼ˆ0.0-1.0ï¼‰
                    )
                )
            )
        ],
        temperature=0.1,
        max_output_tokens=2000,
        system_instruction=system_instruction
    )
)
```

**æ–¹æ¡ˆ Bï¼šè¨­å®šå›ºå®šæ•¸é‡ï¼ˆä¾‹å¦‚ï¼š10 ç­†ï¼‰**

```python
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store_id],
                    # æ–°å¢ï¼šå‹•æ…‹æª¢ç´¢é…ç½®
                    dynamic_retrieval_config=types.DynamicRetrievalConfig(
                        mode='MODE_DYNAMIC',
                        dynamic_threshold=0.3
                    )
                )
            )
        ],
        temperature=0.1,
        max_output_tokens=4000,  # å¢åŠ è¼¸å‡º token æ•¸é‡ä»¥å®¹ç´æ›´å¤šçµæœ
        system_instruction=system_instruction
    )
)
```

**æ–¹æ¡ˆ Cï¼šå®Œå…¨ä¸é™åˆ¶ï¼ˆé¡¯ç¤ºæ‰€æœ‰ç›¸é—œçµæœï¼‰**

```python
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=question,
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store_id],
                    # æ–°å¢ï¼šå‹•æ…‹æª¢ç´¢é…ç½®ï¼ˆç„¡é™åˆ¶ï¼‰
                    dynamic_retrieval_config=types.DynamicRetrievalConfig(
                        mode='MODE_UNSPECIFIED',  # ä¸æŒ‡å®šæ¨¡å¼ï¼Œè¿”å›æ‰€æœ‰ç›¸é—œçµæœ
                        dynamic_threshold=0.0     # æœ€ä½é–¾å€¼ï¼ŒåŒ…å«æ›´å¤šçµæœ
                    )
                )
            )
        ],
        temperature=0.1,
        max_output_tokens=8000,  # å¤§å¹…å¢åŠ è¼¸å‡ºé™åˆ¶
        system_instruction=system_instruction
    )
)
```

---

## ğŸ“‹ åƒæ•¸èªªæ˜

### `DynamicRetrievalConfig` åƒæ•¸

| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | å»ºè­°å€¼ |
|-----|------|--------|--------|
| `mode` | æª¢ç´¢æ¨¡å¼ | `MODE_DYNAMIC` | `MODE_UNSPECIFIED`ï¼ˆä¸é™åˆ¶ï¼‰ |
| `dynamic_threshold` | ç›¸é—œæ€§é–¾å€¼ï¼ˆ0.0-1.0ï¼‰ | 0.7 | `0.0`ï¼ˆåŒ…å«æ›´å¤šçµæœï¼‰ |

### `max_output_tokens` èª¿æ•´

è¿”å›æ›´å¤šçµæœéœ€è¦æ›´å¤šè¼¸å‡ºç©ºé–“ï¼š

- é è¨­ï¼š2000 tokensï¼ˆç´„ 3 ç­†çµæœï¼‰
- å»ºè­°ï¼š4000-8000 tokensï¼ˆç´„ 5-10 ç­†çµæœï¼‰
- æœ€å¤§ï¼š32768 tokensï¼ˆgemini-2.0-flash-001 æ”¯æ´ï¼‰

---

## ğŸ” å®Œæ•´ç¯„ä¾‹ç¨‹å¼ç¢¼

```python
from google import genai
from google.genai import types
import os

def query_rag_unlimited(question: str, store_id: str) -> dict:
    """
    åŸ·è¡Œ RAG æŸ¥è©¢ï¼ˆä¸é™åˆ¶çµæœæ•¸é‡ï¼‰

    Args:
        question: æŸ¥è©¢å•é¡Œ
        store_id: File Search Store ID

    Returns:
        æŸ¥è©¢çµæœï¼ˆåŒ…å«å›ç­”å’Œæ‰€æœ‰åƒè€ƒæ–‡ä»¶ï¼‰
    """

    client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=question,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    file_search=types.FileSearch(
                        file_search_store_names=[store_id],
                        # é—œéµï¼šè¨­å®šå‹•æ…‹æª¢ç´¢ç‚ºä¸é™åˆ¶æ¨¡å¼
                        dynamic_retrieval_config=types.DynamicRetrievalConfig(
                            mode='MODE_UNSPECIFIED',
                            dynamic_threshold=0.0
                        )
                    )
                )
            ],
            temperature=0.1,
            max_output_tokens=8000,  # æ”¯æ´æ›´å¤šçµæœ
            system_instruction="""ä½ æ˜¯é‡‘ç®¡æœƒè£ç½°æ¡ˆä»¶æŸ¥è©¢åŠ©æ‰‹ã€‚
è«‹æä¾›å®Œæ•´ã€çµæ§‹åŒ–çš„æŸ¥è©¢çµæœï¼ŒåŒ…å«æ‰€æœ‰ç›¸é—œæ¡ˆä»¶çš„è©³ç´°è³‡è¨Šã€‚"""
        )
    )

    # è§£æçµæœ
    result = {
        'text': response.text,
        'sources': []
    }

    # æå–åƒè€ƒæ–‡ä»¶
    if hasattr(response, 'candidates') and response.candidates:
        candidate = response.candidates[0]
        if hasattr(candidate, 'grounding_metadata'):
            metadata = candidate.grounding_metadata
            if hasattr(metadata, 'grounding_chunks'):
                for chunk in metadata.grounding_chunks:
                    if hasattr(chunk, 'retrieved_context'):
                        context = chunk.retrieved_context
                        result['sources'].append({
                            'filename': getattr(context, 'uri', ''),
                            'snippet': getattr(context, 'text', '')[:500]
                        })

    return result

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == '__main__':
    store_id = 'fileSearchStores/fscpenalties-tu709bvr1qti'
    question = 'ä¸‰å•†ç¾é‚¦äººå£½ è³‡æœ¬é©è¶³ç‡'

    result = query_rag_unlimited(question, store_id)

    print(f"å›ç­”:\n{result['text']}\n")
    print(f"åƒè€ƒæ–‡ä»¶æ•¸é‡: {len(result['sources'])} ç­†")
```

---

## âœ… ä¿®æ”¹æ­¥é©Ÿ

### 1. æ‰¾åˆ° app.py ä¸­çš„æŸ¥è©¢å‡½æ•¸

æœå°‹é—œéµå­—ï¼š`generate_content` æˆ– `GenerateContentConfig`

### 2. åŠ å…¥ `dynamic_retrieval_config` åƒæ•¸

åœ¨ `FileSearch` ä¸­æ–°å¢ï¼š

```python
dynamic_retrieval_config=types.DynamicRetrievalConfig(
    mode='MODE_UNSPECIFIED',
    dynamic_threshold=0.0
)
```

### 3. èª¿æ•´ `max_output_tokens`

å°‡ `max_output_tokens` å¾ 2000 æé«˜åˆ° 8000

### 4. æ¸¬è©¦

```bash
cd ~/Projects/FSC-Penalties-Deploy
streamlit run app.py
```

æŸ¥è©¢ã€Œä¸‰å•†ç¾é‚¦äººå£½ è³‡æœ¬é©è¶³ç‡ã€ï¼Œç¢ºèªï¼š
- âœ… é¡¯ç¤ºæ‰€æœ‰ 4 ç­†çµæœï¼ˆä¸å†æ˜¯ã€Œå‰ 3 ç­†ã€ï¼‰
- âœ… çµæœå®Œæ•´é¡¯ç¤ºï¼ˆæ²’æœ‰æˆªæ–·ï¼‰

### 5. æäº¤è®Šæ›´

```bash
git add app.py
git commit -m "fix: ç§»é™¤ RAG æŸ¥è©¢çµæœæ•¸é‡é™åˆ¶ï¼Œé¡¯ç¤ºæ‰€æœ‰ç›¸é—œæ¡ˆä»¶"
git push
```

---

## ğŸ¯ é æœŸæ•ˆæœ

### ä¿®æ”¹å‰
```
æ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼Œä»¥ä¸‹åˆ—å‡ºå‰ 3 ç­†ï¼š

1. [æ¡ˆä»¶è³‡è¨Š]
2. [æ¡ˆä»¶è³‡è¨Š]
3. [æ¡ˆä»¶è³‡è¨Š]
```

### ä¿®æ”¹å¾Œ
```
æ‰¾åˆ° 4 ç­†ç›¸é—œè£ç½°æ¡ˆä»¶ï¼š

1. [æ¡ˆä»¶è³‡è¨Š]
2. [æ¡ˆä»¶è³‡è¨Š]
3. [æ¡ˆä»¶è³‡è¨Š]
4. [æ¡ˆä»¶è³‡è¨Š]
```

---

## ğŸ“š åƒè€ƒè³‡æº

- [Gemini File Search API æ–‡æª”](https://ai.google.dev/api/generate-content#dynamic_retrieval_config)
- [Dynamic Retrieval Config èªªæ˜](https://ai.google.dev/api/caching#DynamicRetrievalConfig)

---

## âš ï¸ æ³¨æ„äº‹é …

1. **API è²»ç”¨**ï¼šè¿”å›æ›´å¤šçµæœæœƒå¢åŠ è¼¸å‡º token ä½¿ç”¨é‡ï¼Œå¯èƒ½å½±éŸ¿ API è²»ç”¨
2. **å›æ‡‰æ™‚é–“**ï¼šæ›´å¤šçµæœå¯èƒ½å»¶é•·æŸ¥è©¢æ™‚é–“ï¼ˆä½†é€šå¸¸å½±éŸ¿ä¸å¤§ï¼‰
3. **UI é¡¯ç¤º**ï¼šç¢ºä¿å‰ç«¯ UI èƒ½å¤ å¦¥å–„é¡¯ç¤ºå¤šç­†çµæœï¼ˆè¶…é 10 ç­†æ™‚è€ƒæ…®åˆ†é ï¼‰

---

**æ›´æ–°æ—¥æœŸ**ï¼š2025-11-15
**é©ç”¨å°ˆæ¡ˆ**ï¼šFSC-Penalties-Deploy (Streamlit)
