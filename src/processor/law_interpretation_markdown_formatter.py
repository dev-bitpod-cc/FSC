"""æ³•ä»¤å‡½é‡‹ Markdown æ ¼å¼åŒ–å™¨ - å°‡æ³•ä»¤å‡½é‡‹è³‡æ–™è½‰æ›ç‚º Gemini å‹å–„çš„ Markdown æ ¼å¼"""

from typing import Dict, Any, List, Optional
from datetime import datetime
from loguru import logger


class LawInterpretationMarkdownFormatter:
    """æ³•ä»¤å‡½é‡‹ Markdown æ ¼å¼åŒ–å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ ¼å¼åŒ–å™¨"""
        self.category_names = {
            'law_amendment': 'ä¿®æ­£',
            'law_enactment': 'è¨‚å®š',
            'law_interpretation_decree': 'å‡½é‡‹',
            'law_clarification': 'æœ‰é—œ',
            'law_repeal': 'å»¢æ­¢',
            'law_publication': 'å…¬å‘Š',  # ç™¼å¸ƒ/å…¬å¸ƒå‹ï¼ˆåŸ announcementï¼‰
            'law_approval': 'æ ¸å‡†',
            'law_adjustment': 'èª¿æ•´',
            'law_notice': 'é€šçŸ¥'
        }

        self.source_names = {
            'fsc_main': 'é‡‘ç®¡æœƒæœ¬æœƒ',
            'bank_bureau': 'éŠ€è¡Œå±€',
            'securities_bureau': 'è­‰åˆ¸æœŸè²¨å±€',
            'insurance_bureau': 'ä¿éšªå±€',
            'examination_bureau': 'æª¢æŸ¥å±€',
            'unknown': 'æœªåˆ†é¡'
        }

    def format_interpretation(self, item: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å–®ç­†æ³•ä»¤å‡½é‡‹ç‚º Markdown

        Args:
            item: æ³•ä»¤å‡½é‡‹è³‡æ–™

        Returns:
            Markdown æ ¼å¼çš„æ–‡å­—
        """
        md_lines = []

        # æ¨™é¡Œ
        title = item.get('title', 'ç„¡æ¨™é¡Œ')
        md_lines.append(f"# {title}\n")

        # æå– metadata
        metadata = item.get('metadata', {})

        # ===== åŸºæœ¬è³‡è¨Šå€å¡Š =====
        md_lines.append("## ğŸ“‹ åŸºæœ¬è³‡è¨Š\n")

        # æ–‡ä»¶ç·¨è™Ÿ
        if 'id' in item:
            md_lines.append(f"- **æ–‡ä»¶ç·¨è™Ÿ**: `{item['id']}`")

        # ç™¼æ–‡å­—è™Ÿ
        doc_number = metadata.get('document_number')
        if doc_number:
            md_lines.append(f"- **ç™¼æ–‡å­—è™Ÿ**: {doc_number}")

        # ç™¼å¸ƒæ—¥æœŸ
        if 'date' in item:
            md_lines.append(f"- **ç™¼å¸ƒæ—¥æœŸ**: {item['date']}")

        # ä¾†æºå–®ä½
        source_raw = item.get('source_raw', '')
        if source_raw:
            md_lines.append(f"- **ä¾†æºå–®ä½**: {source_raw}")

        # æ¨™æº–åŒ–ä¾†æº
        source = metadata.get('source')
        if source:
            source_name = self.source_names.get(source, source)
            md_lines.append(f"- **å–®ä½ä»£ç¢¼**: {source_name}")

        # æ³•ä»¤å‡½é‡‹é¡å‹
        category = metadata.get('category')
        if category:
            category_name = self.category_names.get(category, category)
            md_lines.append(f"- **é¡å‹**: {category_name}")

        # åŸå§‹é€£çµ
        if 'detail_url' in item:
            md_lines.append(f"- **åŸå§‹é€£çµ**: {item['detail_url']}")

        md_lines.append("")  # ç©ºè¡Œ

        # ===== æ³•å¾‹è³‡è¨Š =====
        law_name = metadata.get('law_name')
        if law_name:
            md_lines.append("## ğŸ“œ ç›¸é—œæ³•å¾‹\n")
            md_lines.append(f"- **æ³•å¾‹åç¨±**: {law_name}")

            # ä¿®æ­£/è¨‚å®šæ¢æ–‡
            amended_articles = metadata.get('amended_articles')
            if amended_articles:
                if category == 'law_amendment':
                    md_lines.append(f"- **ä¿®æ­£æ¢æ–‡**: {amended_articles}")
                elif category == 'law_enactment':
                    md_lines.append(f"- **è¨‚å®šæ¢æ–‡**: {amended_articles}")

            # æ³•æ¢åƒç…§
            law_reference = metadata.get('law_reference')
            if law_reference:
                md_lines.append(f"- **æ³•æ¢ä¾æ“š**: {law_reference}")

            md_lines.append("")  # ç©ºè¡Œ

        # ===== å®Œæ•´å…§å®¹ =====
        if 'content' in item:
            content = item['content']

            if isinstance(content, dict) and 'text' in content:
                text = content['text'].strip()
                if text:
                    md_lines.append("## ğŸ“„ å‡½é‡‹å…§å®¹\n")
                    # æ¸…ç†å…§å®¹
                    text = self._clean_content(text)
                    md_lines.append(text)
                    md_lines.append("")

        # ===== é™„ä»¶å€å¡Š =====
        attachments = item.get('attachments', [])

        if attachments:
            md_lines.append("## ğŸ“ ç›¸é—œé™„ä»¶\n")

            for i, att in enumerate(attachments, 1):
                name = att.get('name', 'æœªå‘½å')
                url = att.get('url', '')
                file_type = att.get('type', 'unknown').upper()
                att_classification = att.get('classification', 'other')

                # é™„ä»¶åˆ†é¡èªªæ˜
                classification_labels = {
                    'comparison_table': 'å°ç…§è¡¨',
                    'amended_text': 'ä¿®æ­£æ¢æ–‡',
                    'enacted_text': 'è¨‚å®šæ¢æ–‡',
                    'explanation': 'ä¿®æ­£èªªæ˜',
                    'interpretation': 'å‡½é‡‹å…§å®¹',
                    'other': 'å…¶ä»–'
                }
                classification_label = classification_labels.get(att_classification, 'å…¶ä»–')

                # å¦‚æœæœ‰æœ¬åœ°æª”æ¡ˆè·¯å¾‘ï¼Œä¹Ÿé¡¯ç¤º
                local_path = att.get('local_path')
                if local_path:
                    md_lines.append(f"{i}. **{name}** ([{file_type}]({url})) - *{classification_label}*")
                    md_lines.append(f"   - æœ¬åœ°è·¯å¾‘: `{local_path}`")
                else:
                    md_lines.append(f"{i}. **{name}** ([{file_type}]({url})) - *{classification_label}*")

            md_lines.append("")

        # ===== åˆ†éš”ç·š =====
        md_lines.append("---\n")

        # ===== Metadata footer (æ–¹ä¾¿ RAG æª¢ç´¢) =====
        footer_tags = []

        if 'date' in item:
            footer_tags.append(f"æ—¥æœŸ:{item['date']}")

        if source:
            footer_tags.append(f"ä¾†æº:{source}")

        if category:
            footer_tags.append(f"é¡å‹:{category}")

        if law_name:
            footer_tags.append(f"æ³•å¾‹:{law_name}")

        if doc_number:
            footer_tags.append(f"ç™¼æ–‡å­—è™Ÿ:{doc_number}")

        if footer_tags:
            md_lines.append(f"*æ¨™ç±¤: {' | '.join(footer_tags)}*\n")

        return "\n".join(md_lines)

    def format_batch(self, items: List[Dict[str, Any]], add_toc: bool = True) -> str:
        """
        æ ¼å¼åŒ–å¤šç­†æ³•ä»¤å‡½é‡‹ç‚ºå–®ä¸€ Markdown æ–‡ä»¶

        Args:
            items: æ³•ä»¤å‡½é‡‹è³‡æ–™åˆ—è¡¨
            add_toc: æ˜¯å¦æ–°å¢ç›®éŒ„

        Returns:
            å®Œæ•´çš„ Markdown æ–‡ä»¶
        """
        md_parts = []

        # æ–‡æª”æ¨™é¡Œ
        md_parts.append("# é‡‘ç®¡æœƒæ³•ä»¤å‡½é‡‹å½™ç·¨\n")
        md_parts.append(f"**ç”¢ç”Ÿæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        md_parts.append(f"**å‡½é‡‹æ•¸é‡**: {len(items)} ç­†\n")
        md_parts.append("---\n")

        # ç›®éŒ„ (å¯é¸)
        if add_toc and len(items) > 1:
            md_parts.append("## ğŸ“‘ ç›®éŒ„\n")

            for i, item in enumerate(items, 1):
                title = item.get('title', 'ç„¡æ¨™é¡Œ')
                date = item.get('date', 'N/A')
                # Markdown éŒ¨é» (GitHub style)
                anchor = self._create_anchor(title)
                md_parts.append(f"{i}. [{title}](#{anchor}) - {date}")

            md_parts.append("\n---\n")

        # å…§å®¹
        for i, item in enumerate(items, 1):
            logger.debug(f"æ ¼å¼åŒ–ç¬¬ {i}/{len(items)} ç­†: {item.get('title', 'N/A')[:50]}")

            # æ–°å¢åºè™Ÿæ¨™è¨˜
            md_parts.append(f"\n<!-- å‡½é‡‹ {i}/{len(items)} -->\n")

            # æ ¼å¼åŒ–å–®ç­†
            md_content = self.format_interpretation(item)
            md_parts.append(md_content)

            # åˆ†é ç¬¦è™Ÿ (é™¤äº†æœ€å¾Œä¸€ç­†)
            if i < len(items):
                md_parts.append("\n\n")

        return "\n".join(md_parts)

    def _clean_content(self, text: str) -> str:
        """
        æ¸…ç†å…§å®¹æ–‡å­—

        Args:
            text: åŸå§‹æ–‡å­—

        Returns:
            æ¸…ç†å¾Œçš„æ–‡å­—
        """
        # ç§»é™¤éå¤šç©ºè¡Œ
        lines = text.split('\n')
        cleaned_lines = []
        prev_empty = False

        for line in lines:
            line = line.strip()

            # è·³éé€£çºŒç©ºè¡Œ
            if not line:
                if not prev_empty:
                    cleaned_lines.append('')
                prev_empty = True
            else:
                cleaned_lines.append(line)
                prev_empty = False

        # ç§»é™¤ç¤¾ç¾¤åˆ†äº«ç›¸é—œæ–‡å­—
        filtered_lines = []
        skip_keywords = [
            'FACEBOOK', 'facebook', 'Facebook',
            'Line', 'LINE',
            'Twitter', 'TWITTER',
            'å‹å–„åˆ—å°', 'å›ä¸Šé ', 'ç€è¦½äººæ¬¡', 'æ›´æ–°æ—¥æœŸ',
            'è½‰å¯„', 'åˆ—å°', 'åˆ†äº«',
            'é»é–±', 'ç™¼å¸ƒå–®ä½', 'ç™¼å¸ƒæ—¥æœŸ',
            ':::',  # é‡‘ç®¡æœƒç¶²ç«™çš„ç‰¹æ®Šåˆ†éš”ç¬¦
            'ç¶²ç«™å°è¦½', 'æ„è¦‹ä¿¡ç®±',
            'QRCode',
            'ä¸‹è¼‰',
        ]

        for line in cleaned_lines:
            # è·³éåŒ…å«ä»»ä½•é—œéµå­—çš„è¡Œ
            if any(keyword in line for keyword in skip_keywords):
                continue
            # è·³éåªæœ‰æ¨™é»ç¬¦è™Ÿçš„è¡Œ
            if line and all(c in '.,;:!?()[]{}ã€Œã€ã€ã€â€¦â”€â€”' for c in line):
                continue
            filtered_lines.append(line)

        return '\n'.join(filtered_lines)

    def _create_anchor(self, title: str) -> str:
        """
        å»ºç«‹ Markdown éŒ¨é»

        Args:
            title: æ¨™é¡Œæ–‡å­—

        Returns:
            éŒ¨é» ID
        """
        # GitHub Markdown éŒ¨é»è¦å‰‡:
        # 1. è½‰å°å¯«
        # 2. ç§»é™¤æ¨™é»ç¬¦è™Ÿ
        # 3. ç©ºæ ¼è½‰ -
        import re

        anchor = title.lower()
        # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
        anchor = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', anchor)
        # ç©ºæ ¼è½‰ -
        anchor = re.sub(r'\s+', '-', anchor)

        return anchor

    def save_to_file(self, markdown: str, filepath: str):
        """
        å„²å­˜ Markdown åˆ°æª”æ¡ˆ

        Args:
            markdown: Markdown å…§å®¹
            filepath: æª”æ¡ˆè·¯å¾‘
        """
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown)

            logger.info(f"Markdown å·²å„²å­˜: {filepath}")

        except Exception as e:
            logger.error(f"å„²å­˜ Markdown å¤±æ•—: {e}")
            raise


class BatchLawInterpretationMarkdownFormatter(LawInterpretationMarkdownFormatter):
    """æ‰¹æ¬¡æ³•ä»¤å‡½é‡‹ Markdown æ ¼å¼åŒ–å™¨ - ä¾æ—¥æœŸã€ä¾†æºæˆ–é¡å‹åˆ†æª”"""

    def format_by_date(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰æ—¥æœŸåˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: æ³•ä»¤å‡½é‡‹è³‡æ–™åˆ—è¡¨

        Returns:
            {date: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            date = item.get('date', 'unknown')
            grouped[date].append(item)

        results = {}
        for date, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=False)
            results[date] = md

        logger.info(f"æŒ‰æ—¥æœŸåˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_by_source(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰ä¾†æºå–®ä½åˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: æ³•ä»¤å‡½é‡‹è³‡æ–™åˆ—è¡¨

        Returns:
            {source: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            source = 'unknown'
            if 'metadata' in item and 'source' in item['metadata']:
                source = item['metadata']['source']

            grouped[source].append(item)

        results = {}
        for source, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=True)
            results[source] = md

        logger.info(f"æŒ‰ä¾†æºåˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_by_category(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰å‡½é‡‹é¡å‹åˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: æ³•ä»¤å‡½é‡‹è³‡æ–™åˆ—è¡¨

        Returns:
            {category: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            category = 'unknown'
            if 'metadata' in item and 'category' in item['metadata']:
                category = item['metadata']['category']

            grouped[category].append(item)

        results = {}
        for category, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=True)
            results[category] = md

        logger.info(f"æŒ‰å‡½é‡‹é¡å‹åˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_individual_files(
        self,
        items: List[Dict[str, Any]],
        output_dir: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å°‡æ¯å€‹æ³•ä»¤å‡½é‡‹æ ¼å¼åŒ–ç‚ºç¨ç«‹çš„ Markdown æª”æ¡ˆ
        (ç”¨æ–¼ RAG ä¸Šå‚³,æ¯å€‹å‡½é‡‹éƒ½æœ‰ç¨ç«‹ä¸”èªæ„åŒ–çš„æª”å)

        Args:
            items: æ³•ä»¤å‡½é‡‹è³‡æ–™åˆ—è¡¨
            output_dir: è¼¸å‡ºç›®éŒ„ (é è¨­: data/markdown/law_interpretations_individual)

        Returns:
            çµ±è¨ˆè³‡è¨Š {'total_items': ..., 'created_files': ..., 'output_dir': ...}
        """
        from pathlib import Path
        import re

        # é è¨­è¼¸å‡ºç›®éŒ„
        if not output_dir:
            output_dir = 'data/markdown/law_interpretations_individual'

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"é–‹å§‹æ ¼å¼åŒ–æ³•ä»¤å‡½é‡‹ç‚ºç¨ç«‹æª”æ¡ˆ...")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {output_path}")

        if not items:
            logger.warning("æ²’æœ‰æ³•ä»¤å‡½é‡‹è³‡æ–™")
            return {'total_items': 0, 'created_files': 0, 'output_dir': str(output_path)}

        # ä¾†æºä¸­æ–‡æ˜ å°„
        source_mapping = {
            'bank_bureau': 'éŠ€è¡Œå±€',
            'securities_bureau': 'è­‰åˆ¸æœŸè²¨å±€',
            'insurance_bureau': 'ä¿éšªå±€',
            'examination_bureau': 'æª¢æŸ¥å±€',
            'fsc_main': 'é‡‘ç®¡æœƒ',
            'unknown': 'æœªåˆ†é¡'
        }

        # é¡å‹ç°¡ç¨±æ˜ å°„
        category_abbr = {
            'law_amendment': 'ä¿®æ­£',
            'law_enactment': 'è¨‚å®š',
            'law_interpretation_decree': 'å‡½é‡‹',
            'law_clarification': 'æœ‰é—œ',
            'law_repeal': 'å»¢æ­¢',
            'law_publication': 'å…¬å‘Š',  # ç™¼å¸ƒ/å…¬å¸ƒå‹ï¼ˆåŸ announcementï¼‰
            'law_approval': 'æ ¸å‡†',
            'law_adjustment': 'èª¿æ•´',
            'law_notice': 'é€šçŸ¥'
        }

        def sanitize_filename(text: str, max_length: int = 50) -> str:
            """æ¸…ç†æª”å,ç§»é™¤ä¸åˆæ³•å­—å…ƒ"""
            # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•å­—å…ƒ
            text = re.sub(r'[<>:"/\\|?*]', '_', text)
            # ç§»é™¤å‰å¾Œç©ºç™½
            text = text.strip()
            # é™åˆ¶é•·åº¦
            if len(text) > max_length:
                text = text[:max_length]
            return text

        # ç‚ºæ¯å€‹å‡½é‡‹å»ºç«‹ç¨ç«‹æª”æ¡ˆ
        created_files = []

        for item in items:
            try:
                # æ ¼å¼åŒ–å–®å€‹å‡½é‡‹
                md_content = self.format_interpretation(item)

                # å»ºç«‹ç°¡æ½”çš„æª”åï¼ˆç”¨æ–¼ Gemini File Search é¡¯ç¤ºï¼‰
                item_id = item.get('id', 'unknown')
                source = item.get('metadata', {}).get('source', 'unknown')
                source_cn = source_mapping.get(source, source)
                category = item.get('metadata', {}).get('category', 'unknown')
                category_cn = category_abbr.get(category, category)

                # å–®ä½ç°¡ç¨±æ˜ å°„ï¼ˆæå‡æŸ¥è©¢çµæœå¯è®€æ€§ï¼‰
                source_short_mapping = {
                    'éŠ€è¡Œå±€': 'éŠ€',
                    'ä¿éšªå±€': 'ä¿',
                    'è­‰åˆ¸æœŸè²¨å±€': 'è­‰æœŸ',
                    'æª¢æŸ¥å±€': 'æª¢',
                    'é‡‘ç®¡æœƒ': 'é‡‘',
                    'æœªåˆ†é¡': 'å…¶ä»–'
                }
                source_short = source_short_mapping.get(source_cn, source_cn[:2] if source_cn else 'æœªçŸ¥')

                # æª”åæ ¼å¼: {ID}_{å–®ä½ç°¡ç¨±}_{é¡å‹}.md
                # ç¯„ä¾‹: fsc_law_20230315_0045_éŠ€_ä¿®æ­£.md
                filename = f"{item_id}_{source_short}_{category_cn}.md"

                # å¯«å…¥æª”æ¡ˆ
                filepath = output_path / filename
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(md_content)

                created_files.append(str(filepath))
                logger.debug(f"å»ºç«‹æª”æ¡ˆ: {filename}")

            except Exception as e:
                logger.error(f"æ ¼å¼åŒ–é …ç›®å¤±æ•—: {item.get('id', 'unknown')} - {e}")
                continue

        logger.info(f"å®Œæˆ! å…±å»ºç«‹ {len(created_files)} å€‹æª”æ¡ˆ")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {output_path}")

        return {
            'total_items': len(items),
            'created_files': len(created_files),
            'output_dir': str(output_path),
            'files': created_files[:10]  # åªè¿”å›å‰ 10 å€‹æª”æ¡ˆè·¯å¾‘ä½œç‚ºç¯„ä¾‹
        }
