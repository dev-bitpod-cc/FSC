"""è£ç½°æ¡ˆä»¶ Markdown æ ¼å¼åŒ–å™¨ - å°‡è£ç½°æ¡ˆä»¶è³‡æ–™è½‰æ›ç‚º Gemini å‹å–„çš„ Markdown æ ¼å¼"""

from typing import Dict, Any, List, Optional
from datetime import datetime
from loguru import logger


class PenaltyMarkdownFormatter:
    """è£ç½°æ¡ˆä»¶ Markdown æ ¼å¼åŒ–å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ ¼å¼åŒ–å™¨"""
        self.category_names = {
            'internal_control_violation': 'å…§éƒ¨æ§åˆ¶ç¼ºå¤±',
            'compliance_violation': 'æ³•ä»¤éµå¾ªç¼ºå¤±',
            'capital_adequacy': 'è³‡æœ¬é©è¶³ç‡ä¸è¶³',
            'aml_violation': 'æ´—éŒ¢é˜²åˆ¶ç¼ºå¤±',
            'information_security': 'è³‡è¨Šå®‰å…¨ç¼ºå¤±',
            'consumer_protection': 'æ¶ˆè²»è€…ä¿è­·ç¼ºå¤±',
            'financial_reporting': 'è²¡å‹™å ±å‘Šä¸å¯¦',
            'licensing_violation': 'è¨±å¯åŸ·ç…§é•è¦',
            'operational_violation': 'æ¥­å‹™ç¶“ç‡Ÿé•è¦',
            'other': 'å…¶ä»–é•è¦'
        }

        self.source_names = {
            'fsc_main': 'é‡‘ç®¡æœƒæœ¬æœƒ',
            'bank_bureau': 'éŠ€è¡Œå±€',
            'securities_bureau': 'è­‰åˆ¸æœŸè²¨å±€',
            'insurance_bureau': 'ä¿éšªå±€',
            'examination_bureau': 'æª¢æŸ¥å±€',
            'unknown': 'æœªåˆ†é¡'
        }

        self.entity_type_names = {
            'insurance': 'ä¿éšªæ¥­',
            'bank': 'éŠ€è¡Œæ¥­',
            'securities': 'è­‰åˆ¸æœŸè²¨æ¥­',
            'trust': 'ä¿¡è¨—æ¥­',
            'bills_finance': 'ç¥¨åˆ¸æ¥­',
            'financial_holding': 'é‡‘æ§å…¬å¸',
            'other': 'å…¶ä»–'
        }

    def format_penalty(self, item: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å–®ç­†è£ç½°æ¡ˆä»¶ç‚º Markdown

        Args:
            item: è£ç½°æ¡ˆä»¶è³‡æ–™

        Returns:
            Markdown æ ¼å¼çš„æ–‡å­—
        """
        md_lines = []

        # æ¨™é¡Œ
        title = item.get('title', 'ç„¡æ¨™é¡Œ')
        md_lines.append(f"# {title}\n")

        # æå– metadata
        metadata = item.get('metadata', {})

        # ===== åŸºæœ¬è³‡è¨Šå€å¡Š =====
        md_lines.append("## ğŸ“‹ åŸºæœ¬è³‡è¨Š\n")

        # æ–‡ä»¶ç·¨è™Ÿ
        if 'id' in item:
            md_lines.append(f"- **æ–‡ä»¶ç·¨è™Ÿ**: `{item['id']}`")

        # ç™¼æ–‡å­—è™Ÿ
        doc_number = metadata.get('doc_number')
        if doc_number:
            md_lines.append(f"- **ç™¼æ–‡å­—è™Ÿ**: {doc_number}")

        # ç™¼å¸ƒæ—¥æœŸ
        if 'date' in item:
            md_lines.append(f"- **ç™¼å¸ƒæ—¥æœŸ**: {item['date']}")

        # ä¾†æºå–®ä½
        source_raw = item.get('source_raw', '')
        if source_raw:
            md_lines.append(f"- **ä¾†æºå–®ä½**: {source_raw}")

        # æ¨™æº–åŒ–ä¾†æº
        source = metadata.get('source')
        if source:
            source_name = self.source_names.get(source, source)
            md_lines.append(f"- **å–®ä½ä»£ç¢¼**: {source_name}")

        # åŸå§‹é€£çµ
        if 'detail_url' in item:
            md_lines.append(f"- **åŸå§‹é€£çµ**: {item['detail_url']}")

        md_lines.append("")  # ç©ºè¡Œ

        # ===== è¢«è™•åˆ†äººè³‡è¨Š =====
        penalized_entity = metadata.get('penalized_entity', {})
        if penalized_entity and penalized_entity.get('name'):
            md_lines.append("## ğŸ‘¤ è¢«è™•åˆ†å°è±¡\n")

            name = penalized_entity.get('name')
            if name:
                md_lines.append(f"- **åç¨±**: {name}")

            entity_type = penalized_entity.get('type')
            if entity_type:
                type_name = self.entity_type_names.get(entity_type, entity_type)
                md_lines.append(f"- **æ¥­åˆ¥**: {type_name}")

            tax_id = penalized_entity.get('tax_id')
            if tax_id:
                md_lines.append(f"- **çµ±ä¸€ç·¨è™Ÿ**: {tax_id}")

            md_lines.append("")  # ç©ºè¡Œ

        # ===== è™•åˆ†å…§å®¹ =====
        md_lines.append("## âš–ï¸ è™•åˆ†å…§å®¹\n")

        # è™•åˆ†é‡‘é¡
        penalty_amount = metadata.get('penalty_amount')
        penalty_amount_text = metadata.get('penalty_amount_text')

        if penalty_amount or penalty_amount_text:
            if penalty_amount_text:
                md_lines.append(f"- **è™•åˆ†é‡‘é¡**: {penalty_amount_text}")
            elif penalty_amount:
                # æ ¼å¼åŒ–æ•¸å­—
                formatted_amount = f"{penalty_amount:,}"
                md_lines.append(f"- **è™•åˆ†é‡‘é¡**: æ–°è‡ºå¹£ {formatted_amount} å…ƒ")

        # é•è¦é¡å‹
        category = metadata.get('category')
        if category:
            category_name = self.category_names.get(category, category)
            md_lines.append(f"- **é•è¦é¡å‹**: {category_name}")

        # æª¢æŸ¥å ±å‘Šç·¨è™Ÿ
        inspection_report = metadata.get('inspection_report')
        if inspection_report:
            md_lines.append(f"- **æª¢æŸ¥å ±å‘Šç·¨è™Ÿ**: {inspection_report}")

        md_lines.append("")  # ç©ºè¡Œ

        # ===== é•è¦äº‹ç”± =====
        violation = metadata.get('violation', {})
        if violation and (violation.get('summary') or violation.get('details')):
            md_lines.append("## ğŸ“ é•è¦äº‹ç”±\n")

            summary = violation.get('summary')
            if summary:
                md_lines.append(f"**æ‘˜è¦**: {summary}\n")

            details = violation.get('details')
            if details:
                md_lines.append("**è©³ç´°èªªæ˜**:\n")
                # æ¸…ç†è©³ç´°å…§å®¹
                cleaned_details = self._clean_content(details)
                md_lines.append(cleaned_details)

            md_lines.append("")  # ç©ºè¡Œ

        # ===== æ³•æ¢ä¾æ“š =====
        legal_basis = metadata.get('legal_basis', [])
        if legal_basis:
            md_lines.append("## ğŸ“œ æ³•æ¢ä¾æ“š\n")

            for i, law in enumerate(legal_basis, 1):
                md_lines.append(f"{i}. {law}")

            md_lines.append("")  # ç©ºè¡Œ

        # ===== å®Œæ•´å…§å®¹ =====
        if 'content' in item:
            content = item['content']

            if isinstance(content, dict) and 'text' in content:
                text = content['text'].strip()
                if text:
                    md_lines.append("## ğŸ“„ å®Œæ•´å…§å®¹\n")
                    # æ¸…ç†å…§å®¹
                    text = self._clean_content(text)
                    md_lines.append(text)
                    md_lines.append("")

        # ===== é™„ä»¶å€å¡Š =====
        attachments = item.get('attachments', [])
        if attachments:
            md_lines.append("## ğŸ“ ç›¸é—œé™„ä»¶\n")

            for i, att in enumerate(attachments, 1):
                name = att.get('name', 'æœªå‘½å')
                url = att.get('url', '')
                file_type = att.get('type', 'unknown').upper()

                # å¦‚æœæœ‰æœ¬åœ°æª”æ¡ˆè·¯å¾‘ï¼Œä¹Ÿé¡¯ç¤º
                local_path = att.get('local_path')
                if local_path:
                    md_lines.append(f"{i}. **{name}** ([{file_type}]({url}))")
                    md_lines.append(f"   - æœ¬åœ°è·¯å¾‘: `{local_path}`")
                else:
                    md_lines.append(f"{i}. **{name}** ([{file_type}]({url}))")

            md_lines.append("")

        # ===== åˆ†éš”ç·š =====
        md_lines.append("---\n")

        # ===== Metadata footer (æ–¹ä¾¿ RAG æª¢ç´¢) =====
        footer_tags = []

        if 'date' in item:
            footer_tags.append(f"æ—¥æœŸ:{item['date']}")

        if source:
            footer_tags.append(f"ä¾†æº:{source}")

        if category:
            footer_tags.append(f"é¡å‹:{category}")

        if penalized_entity.get('name'):
            footer_tags.append(f"è¢«è™•åˆ†äºº:{penalized_entity['name']}")

        if penalty_amount:
            footer_tags.append(f"é‡‘é¡:{penalty_amount}")

        if footer_tags:
            md_lines.append(f"*æ¨™ç±¤: {' | '.join(footer_tags)}*\n")

        return "\n".join(md_lines)

    def format_batch(self, items: List[Dict[str, Any]], add_toc: bool = True) -> str:
        """
        æ ¼å¼åŒ–å¤šç­†è£ç½°æ¡ˆä»¶ç‚ºå–®ä¸€ Markdown æ–‡ä»¶

        Args:
            items: è£ç½°æ¡ˆä»¶è³‡æ–™åˆ—è¡¨
            add_toc: æ˜¯å¦æ–°å¢ç›®éŒ„

        Returns:
            å®Œæ•´çš„ Markdown æ–‡ä»¶
        """
        md_parts = []

        # æ–‡æª”æ¨™é¡Œ
        md_parts.append("# é‡‘ç®¡æœƒè£ç½°æ¡ˆä»¶å½™ç·¨\n")
        md_parts.append(f"**ç”¢ç”Ÿæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        md_parts.append(f"**æ¡ˆä»¶æ•¸é‡**: {len(items)} ç­†\n")
        md_parts.append("---\n")

        # ç›®éŒ„ (å¯é¸)
        if add_toc and len(items) > 1:
            md_parts.append("## ğŸ“‘ ç›®éŒ„\n")

            for i, item in enumerate(items, 1):
                title = item.get('title', 'ç„¡æ¨™é¡Œ')
                date = item.get('date', 'N/A')
                # Markdown éŒ¨é» (GitHub style)
                anchor = self._create_anchor(title)
                md_parts.append(f"{i}. [{title}](#{anchor}) - {date}")

            md_parts.append("\n---\n")

        # å…§å®¹
        for i, item in enumerate(items, 1):
            logger.debug(f"æ ¼å¼åŒ–ç¬¬ {i}/{len(items)} ç­†: {item.get('title', 'N/A')[:50]}")

            # æ–°å¢åºè™Ÿæ¨™è¨˜
            md_parts.append(f"\n<!-- æ¡ˆä»¶ {i}/{len(items)} -->\n")

            # æ ¼å¼åŒ–å–®ç­†
            md_content = self.format_penalty(item)
            md_parts.append(md_content)

            # åˆ†é ç¬¦è™Ÿ (é™¤äº†æœ€å¾Œä¸€ç­†)
            if i < len(items):
                md_parts.append("\n\n")

        return "\n".join(md_parts)

    def _clean_content(self, text: str) -> str:
        """
        æ¸…ç†å…§å®¹æ–‡å­—

        Args:
            text: åŸå§‹æ–‡å­—

        Returns:
            æ¸…ç†å¾Œçš„æ–‡å­—
        """
        # ç§»é™¤éå¤šç©ºè¡Œ
        lines = text.split('\n')
        cleaned_lines = []
        prev_empty = False

        for line in lines:
            line = line.strip()

            # è·³éé€£çºŒç©ºè¡Œ
            if not line:
                if not prev_empty:
                    cleaned_lines.append('')
                prev_empty = True
            else:
                cleaned_lines.append(line)
                prev_empty = False

        # ç§»é™¤ç¤¾ç¾¤åˆ†äº«ç›¸é—œæ–‡å­—
        filtered_lines = []
        skip_keywords = ['FACEBOOK', 'Line', 'Twitter', 'å‹å–„åˆ—å°', 'å›ä¸Šé ', 'ç€è¦½äººæ¬¡', 'æ›´æ–°æ—¥æœŸ']

        for line in cleaned_lines:
            if not any(keyword in line for keyword in skip_keywords):
                filtered_lines.append(line)

        return '\n'.join(filtered_lines)

    def _create_anchor(self, title: str) -> str:
        """
        å»ºç«‹ Markdown éŒ¨é»

        Args:
            title: æ¨™é¡Œæ–‡å­—

        Returns:
            éŒ¨é» ID
        """
        # GitHub Markdown éŒ¨é»è¦å‰‡:
        # 1. è½‰å°å¯«
        # 2. ç§»é™¤æ¨™é»ç¬¦è™Ÿ
        # 3. ç©ºæ ¼è½‰ -
        import re

        anchor = title.lower()
        # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
        anchor = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', anchor)
        # ç©ºæ ¼è½‰ -
        anchor = re.sub(r'\s+', '-', anchor)

        return anchor

    def save_to_file(self, markdown: str, filepath: str):
        """
        å„²å­˜ Markdown åˆ°æª”æ¡ˆ

        Args:
            markdown: Markdown å…§å®¹
            filepath: æª”æ¡ˆè·¯å¾‘
        """
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown)

            logger.info(f"Markdown å·²å„²å­˜: {filepath}")

        except Exception as e:
            logger.error(f"å„²å­˜ Markdown å¤±æ•—: {e}")
            raise


class BatchPenaltyMarkdownFormatter(PenaltyMarkdownFormatter):
    """æ‰¹æ¬¡è£ç½°æ¡ˆä»¶ Markdown æ ¼å¼åŒ–å™¨ - ä¾æ—¥æœŸã€ä¾†æºæˆ–é•è¦é¡å‹åˆ†æª”"""

    def format_by_date(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰æ—¥æœŸåˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: è£ç½°æ¡ˆä»¶è³‡æ–™åˆ—è¡¨

        Returns:
            {date: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            date = item.get('date', 'unknown')
            grouped[date].append(item)

        results = {}
        for date, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=False)
            results[date] = md

        logger.info(f"æŒ‰æ—¥æœŸåˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_by_source(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰ä¾†æºå–®ä½åˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: è£ç½°æ¡ˆä»¶è³‡æ–™åˆ—è¡¨

        Returns:
            {source: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            source = 'unknown'
            if 'metadata' in item and 'source' in item['metadata']:
                source = item['metadata']['source']

            grouped[source].append(item)

        results = {}
        for source, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=True)
            results[source] = md

        logger.info(f"æŒ‰ä¾†æºåˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_by_category(self, items: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        æŒ‰é•è¦é¡å‹åˆ†çµ„ä¸¦æ ¼å¼åŒ–

        Args:
            items: è£ç½°æ¡ˆä»¶è³‡æ–™åˆ—è¡¨

        Returns:
            {category: markdown_content} å­—å…¸
        """
        from collections import defaultdict

        grouped = defaultdict(list)

        for item in items:
            category = 'unknown'
            if 'metadata' in item and 'category' in item['metadata']:
                category = item['metadata']['category']

            grouped[category].append(item)

        results = {}
        for category, group_items in grouped.items():
            md = self.format_batch(group_items, add_toc=True)
            results[category] = md

        logger.info(f"æŒ‰é•è¦é¡å‹åˆ†çµ„å®Œæˆ: {len(results)} å€‹æª”æ¡ˆ")
        return results

    def format_individual_files(
        self,
        items: List[Dict[str, Any]],
        output_dir: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å°‡æ¯å€‹è£ç½°æ¡ˆä»¶æ ¼å¼åŒ–ç‚ºç¨ç«‹çš„ Markdown æª”æ¡ˆ
        (æ¨è–¦ç”¨æ–¼ RAG ä¸Šå‚³,æ¯å€‹æ¡ˆä»¶éƒ½æœ‰ç¨ç«‹ä¸”èªæ„åŒ–çš„æª”å)

        Args:
            items: è£ç½°æ¡ˆä»¶è³‡æ–™åˆ—è¡¨
            output_dir: è¼¸å‡ºç›®éŒ„ (é è¨­: data/markdown/penalties_individual)

        Returns:
            çµ±è¨ˆè³‡è¨Š {'total_items': ..., 'created_files': ..., 'output_dir': ...}
        """
        from pathlib import Path
        import re

        # é è¨­è¼¸å‡ºç›®éŒ„
        if not output_dir:
            output_dir = 'data/markdown/penalties_individual'

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"é–‹å§‹æ ¼å¼åŒ–è£ç½°æ¡ˆä»¶ç‚ºç¨ç«‹æª”æ¡ˆ...")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {output_path}")

        if not items:
            logger.warning("æ²’æœ‰è£ç½°æ¡ˆä»¶è³‡æ–™")
            return {'total_items': 0, 'created_files': 0, 'output_dir': str(output_path)}

        # ä¾†æºä¸­æ–‡æ˜ å°„
        source_mapping = {
            'bank_bureau': 'éŠ€è¡Œå±€',
            'securities_bureau': 'è­‰åˆ¸æœŸè²¨å±€',
            'insurance_bureau': 'ä¿éšªå±€',
            'examination_bureau': 'æª¢æŸ¥å±€',
            'fsc_main': 'é‡‘ç®¡æœƒ',
            'unknown': 'æœªåˆ†é¡'
        }

        def sanitize_filename(text: str, max_length: int = 50) -> str:
            """æ¸…ç†æª”å,ç§»é™¤ä¸åˆæ³•å­—å…ƒ"""
            # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•å­—å…ƒ
            text = re.sub(r'[<>:"/\\|?*]', '_', text)
            # ç§»é™¤å‰å¾Œç©ºç™½
            text = text.strip()
            # é™åˆ¶é•·åº¦
            if len(text) > max_length:
                text = text[:max_length]
            return text

        # ç‚ºæ¯å€‹æ¡ˆä»¶å»ºç«‹ç¨ç«‹æª”æ¡ˆ
        created_files = []

        for item in items:
            try:
                # æ ¼å¼åŒ–å–®å€‹æ¡ˆä»¶
                md_content = self.format_penalty(item)

                # å»ºç«‹ç°¡æ½”çš„æª”åï¼ˆç”¨æ–¼ Gemini File Search é¡¯ç¤ºï¼‰
                item_id = item.get('id', 'unknown')
                source = item.get('metadata', {}).get('source', 'unknown')
                source_cn = source_mapping.get(source, source)

                # å–®ä½ç°¡ç¨±æ˜ å°„ï¼ˆæå‡æŸ¥è©¢çµæœå¯è®€æ€§ï¼‰
                source_abbr = {
                    'éŠ€è¡Œå±€': 'éŠ€',
                    'ä¿éšªå±€': 'ä¿',
                    'è­‰åˆ¸æœŸè²¨å±€': 'è­‰æœŸ',
                    'æª¢æŸ¥å±€': 'æª¢',
                    'æœªåˆ†é¡': 'å…¶ä»–'
                }
                source_short = source_abbr.get(source_cn, source_cn[:2] if source_cn else 'æœªçŸ¥')

                # æª”åæ ¼å¼: {ID}_{å–®ä½ç°¡ç¨±}.md
                # ç¯„ä¾‹: fsc_pen_20230315_0045_éŠ€.md
                filename = f"{item_id}_{source_short}.md"

                # å¯«å…¥æª”æ¡ˆ
                filepath = output_path / filename
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(md_content)

                created_files.append(str(filepath))
                logger.debug(f"å»ºç«‹æª”æ¡ˆ: {filename}")

            except Exception as e:
                logger.error(f"æ ¼å¼åŒ–é …ç›®å¤±æ•—: {item.get('id', 'unknown')} - {e}")
                continue

        logger.info(f"å®Œæˆ! å…±å»ºç«‹ {len(created_files)} å€‹æª”æ¡ˆ")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {output_path}")

        return {
            'total_items': len(items),
            'created_files': len(created_files),
            'output_dir': str(output_path),
            'files': created_files[:10]  # åªè¿”å›å‰ 10 å€‹æª”æ¡ˆè·¯å¾‘ä½œç‚ºç¯„ä¾‹
        }
